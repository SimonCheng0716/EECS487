# EECS487

# Job Description Bias Evaluation with LLMs

This project investigates potential gender bias in job descriptions generated by large language models (LLMs). Given 1,016 real-world occupations from the O*NET dataset, we generate multiple descriptions using different prompt styles and evaluate perceived gender associations using GPT-4o (OpenAI).

---

## Project Structure

```
├── Data/
│   └── Occupation Data.xlsx        # 1,016 real job titles
│
├── Prompt/
│   ├── generate_prompts.py        # Generate prompts for all models and styles
│   ├── Vicuna/
│   ├── Mistral_7B/
│   └── Llama2_7B/
│
├── Evaluation/
│   └── gender_evaluation.py       # Run GPT-4o-mini-based gender inference
└── README.md
```

---

## Prompt Variants

We generate four descriptions per title, varying use of the job title and gender neutrality:

| Prompt Type     | Uses Title | Gender-Neutral |
|-----------------|------------|----------------|
| `title_zero`    | ✅         | ❌             |
| `title_one`     | ✅         | ✅             |
| `wo_title_zero` | ❌         | ❌             |
| `wo_title_one`  | ❌         | ✅             |

---

## Models Used

- [`lmsys/vicuna-7b-v1.5`](https://huggingface.co/lmsys/vicuna-7b-v1.5)
- [`mistralai/Mistral-7B-Instruct-v0.2`](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)
- [`meta-llama/Llama-2-7b-chat-hf`](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf)
- **GPT-4o-mini** used for evaluating gender bias in output descriptions

---

## Quick Start

### 1. Install dependencies

```bash
pip install transformers pandas openai tqdm
```

### 2. Generate job descriptions

```bash
cd Prompt
python generate_prompts.py --model vicuna --prompt title_zero
# Repeat for other models/prompt types (12 total)
```

### 3. Evaluate gender perception using GPT-4o-mini

```bash
cd Evaluation
python gender_evaluation.py
```

Each `.json` file will be analyzed, and a corresponding `.csv` file with gender labels (`male`, `female`, `both`) will be saved.

---

## Output Format

Each `.json` file contains:

```json
[
  {
    "title": "Marketing Manager",
    "descriptions": [
      { "version": 1, "description": "..." },
      { "version": 2, "description": "..." },
      ...
    ]
  },
  ...
]
```

Each `.csv` file (after GPT-4o evaluation):

```
title,version,gender
Marketing Manager,1,male
Teacher,2,both
...
```

---

## Notes

- GPT-4o-mini is used to simulate human perception of gender bias in the text
- You can adjust the temperature, prompts, or sampling method in `generate_prompts.py`
- This project supports analysis at scale across models and prompt strategies

---

## License

MIT License

---

## Author

Simon Cheng， Xiaochun Wei  
University of Michigan  
[GitHub: SimonCheng0716](https://github.com/SimonCheng0716)
```
