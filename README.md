# EECS487: Exploring Gender Bias in LLM-Generated Job Descriptions

This project investigates potential gender biases in job descriptions generated by large language models (LLMs). By analyzing outputs from various LLMs, the study aims to understand how different prompt designs influence gender associations in generated content.îˆ†

## ğŸ“ Project Structure

- **Data/**:îˆƒContains `Occupation Data.xlsx` with 1,016 real-world job titles sourced from the O*NET databaseîˆ„îˆ†

- **Prompt/**:
  - `generate_prompts.py`:îˆƒScript to generate prompts for all models and stylesîˆ„
  - `Vicuna/`, `Mistral_7B/`, `Llama2_7B/`:îˆƒDirectories containing prompts tailored for each respective modelîˆ„îˆ†

- **Evaluation/**:
  - `gender_evaluation.py`:îˆƒScript utilizing GPT-4o-mini for gender inference on generated descriptionsîˆ„îˆ†

- **README.md**:îˆƒProvides an overview and instructions for using the projectîˆ„îˆ†

## ğŸ§ª Prompt Variants
îˆƒThe project employs four prompt variants to generate job description:îˆ„îˆ†

| Prompt Type    | Includes Job Title | Gender-Neutral |
|----------------|--------------------|----------------|
| `title_zero`   | âœ…                 | âŒ             |
| `title_one`    | âœ…                 | âœ…             |
| `wo_title_zero`| âŒ                 | âŒ             |
| `wo_title_one` | âŒ                 | âœ…             |
îˆƒEach variant is designed to assess the impact of prompt structure on the gender associations in the generated conten.îˆ„îˆ†

## ğŸ“Š Evaluation Methodology

- **Assessment Tool*: îˆƒGPT-4o-mini is used to infer the perceived gender from each generated job descriptin.îˆ„îˆ†

- **Metrics*: îˆƒThe analysis focuses on the distribution of gender associations (male, female, both) across different models and prompt typs.îˆ„îˆ†

## ğŸ“ˆ Visualization & Resuls

îˆƒThe project includes scripts to generate visualizations and tables that illustrate the gender distribution in the generated job descriptin.îˆ„ îˆƒThese outputs help in identifying patterns and biases present in the LLMs' outpts.îˆ„îˆ†

## ğŸš€ Getting Started

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/SimonCheng0716/EECS487.git
   cd EECS487
   ```

2. **Install Dependencies**:
   Ensure you have Python installed. Then, install the required packages:
   ```bash
   pip install -r requirements.txt
   ```
îˆ†

3. **Generate Prompts**:
   Run the prompt generation script:
   ```bash
   python Prompt/generate_prompts.py
   ```
îˆ†

4. **Run Evaluations**:
   Execute the gender evaluation script:
   ```bash
   python Evaluation/gender_evaluation.py
   ```
îˆ†

5. **Visualize Results**:
   Use the provided scripts to generate visualizations and analyze the results.

## ğŸ¤ Contribuing

îˆƒContributions are wecme!îˆ„ îˆƒPlease open an issue or submit a pull request for any enhancements or bug ixes.îˆ„îˆ†

## ğŸ“„ Liense

îˆƒThis project is licensed under the MIT Lcense.îˆ„îˆ†
---

îˆƒThis README provides a comprehensive overview of the project, its structure, and instructions for replication and anlsis.îˆ„ îˆƒIt is designed to be clear and informative for users and contributorsalike.îˆ„îˆ† 
